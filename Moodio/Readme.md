# Music Playback based on Emotion Recognition - Moodio

## Team Members:
- **Fardin Saad** 
- **Ahmed Rafayet** 
- **Alamin Shaheen** 
- **Rahat Anwar Khan** 

---

## HCI Project
This project was developed in our final year for the Human-computer Interaction course. The **Moodio** project is focused on emotion recognition from speech to enable music playback based on detected emotions. The goal is to enhance the user's mood by playing songs appropriate for their emotional state. For instance, if the user's speech suggests they are feeling sad, a happy song will be played to improve their mood. This project addresses two key problems:
1. Helping users feel better by selecting mood-enhancing music.
2. Simplifying the process of finding the right song based on the user's emotional state.

## Introduction
**Moodio** is an Android-based application that uses Human-Computer Interaction (HCI) principles to recognize emotions from the user's speech and play music accordingly. The user interacts with the system by answering a series of questions, which are processed to detect their emotions. The system then plays a song based on the detected emotion, aiming to adjust the user's mood.

### Key Features:
- **Emotion Detection**: Recognizes emotions from speech and plays music based on those emotions.
- **Mood Enhancement**: Plays a happy song if a sad emotion is detected.
- **Structured Interaction**: Users answer questions, and their speech is analyzed to determine their emotional state.

---

## Methodology
The development of **Moodio** followed a **User-Centered Design** approach. Data was gathered using a variety of techniques, including:
1. **Unstructured Interviews**
2. **Focus Groups**
3. **Questionnaires**
4. **Statistics from the Internet**

### Requirement Gathering:
- We conducted interviews and focus groups at **IUT** and **BRAC University** to understand the requirements of potential users.
- We identified the target audience for the app to be users between the ages of 13 to 28 years old.

### Prototyping:
- **Low-Fidelity Prototypes** were created using **Balsamiq** to generate wireframes, enabling us to design the basic layout and structure of the app's interface.
- The interactive prototype asked users questions and analyzed their speech to detect emotions, followed by playing a song to suit the detected mood.

---

## Experimental Evaluation
The project gathered data from different age groups (children, teenagers, and adults). We found that users aged 13 to 28 showed the most interest in the app, with males and females having different music preferences. The app is designed to provide different music based on the user's emotional state and gender.

---

## Conclusion
In future iterations of **Moodio**, we plan to improve the speed and accuracy of emotion detection and add more features like playlist creation, music saving, and displaying lyrics. We aim to enhance the user experience by ensuring that the music is aligned with the user's emotional state.

---

## Technologies Used:
- **Programming Language**: Java (for Android)
- **Prototyping Tool**: Balsamiq (for wireframes)
- **HCI Tools**: Xtensio and Balsamiq
